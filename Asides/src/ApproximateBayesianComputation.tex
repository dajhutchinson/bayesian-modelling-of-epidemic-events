\documentclass[11pt,a4paper]{article}

\usepackage[margin=1in, paperwidth=8.3in, paperheight=11.7in]{geometry}
\usepackage{amsmath,amsfonts,fancyhdr,bbm,graphicx,tikz}
\usetikzlibrary{automata,positioning}
\graphicspath{ {img/} }
\usepackage[section,nohyphen]{DomH}
\headertitle{Approximate Bayesian Computation}

\begin{document}

\title{Approximate Bayesian Computation}
\author{Dom Hutchinson}
\date{\today}
\maketitle

\tableofcontents

\section{Intro to ABC}

  \begin{definition}{Approximate Bayesian Computation (ABC)}
    \textit{Approximate Bayesian Computation (ABC)} is a family of computational methods for estimating the posterior of model parameters for \textit{Generative Models}. \textit{Generative Models} are models which can be simulated from but we do not have an explicit definition for their posterior $f_\mathcal{G}(x|\theta)$ (eg most IRL systems).
  \end{definition}

  \begin{proposition}{Motivating Idea\cite{ABC_Annual_Review}}
    \par Consider a set of observations\footnote{From a \textit{Generative Model}}\footnote{Generally these observations are ordered in some way (by the variables of the system) so can be considered a sequence $\{y_t\}_{t\in T}$ where $T$ specifies the variable values in each epoch.} $\mathbf{y}:=(y_1,\dots,y_n)$ where each $y_i\in\reals^m$ is high dimensional. Let $s(\cdot):\reals^m\to\reals^p$ be a mapping (known as a \textit{Summary Statistic}) from the observed data to some lower dimension $p$.
    \par \textit{ABC} aims to infer the joint distribution of parameters $\pmb\theta$ and general summary statistics $\mathbf{s}$, given the observed summary statistics $\mathbf{s}_{obs}:=s(\mathbf{y})$
    \[ p_\epsilon(\pmb\theta,\mathbf{s}|\mathbf{s}_{obs})\propto\underbrace{\pi_0(\pmb\theta)}_\text{Prior}\underbrace{f(s|\pmb\theta)}_\text{Likelihood}K_\epsilon(\|\mathbf{s}-\mathbf{s}_{obs}\|) \]
    where $K_\epsilon(\cdot)$ is a kernel function with scaling parameter $\epsilon$ and $\|\cdot\|$ is a distance measure (e.g. Euclidean).\footnote{The likelihood $f(s|\theta)$ is the only one of these features which is not specified by the user, and thus what we need to ``learn'' it.}
    \par From this joint distribution the posterior for parameters $\pmb\theta$, given the observed summary statistics $\mathbf{s}_{obs}:=s(\mathbf{y})$, can be calculated as
    \[ p_\epsilon(\pmb\theta|\mathbf{s}_{obs})=\int p_\epsilon(\pmb\theta,\mathbf{s}|\mathbf{s}_{obs})d\mathbf{s} \]
    Monte-Carlo Algorithms can be used to sample from this posterior $p_\epsilon(\pmb\theta|\mathbf{s}_{obs})$ without having to explicitly state the likelihood $f(\mathbf{s}|\theta)$. \textit{Numerical Integration} methods can then be used to evaluate the integral\footnote{See \textit{Monte-Carlo Integration} methods: \textit{Uniform Sampling}, \textit{Importance Sampling}}.
  \end{proposition}

  \begin{proposition}{Setup of ABC}
    To perform \textit{ABC} we typically have/define the following features
    \begin{itemize}
      \item A set of observations from a \textit{Generative Model} $\mathbf{y}:=(y_1,\dots,y_n)$ where each $y_i$ is high-dimensional.
      \item A map $s(\cdot)$ which maps the high-dimensional observed data to a lower dimension.
      \item A theorised model with posterior pdf $f_\mathcal{T}(\cdot|\pmb\theta,\x)$ where $\pmb\theta$ are the parameters which we wish to fit to the \textit{Generative Model} using ABC.
      \item A prior $\pi_0(\cdot)$ for the parameters $\pmb\theta$.
      \item A kernel $K_\epsilon(\cdot)$ and a distance measure $\|\cdot\|$.
    \end{itemize}
  \end{proposition}

\subsection{Decisions}

  \begin{remark}{Decisions}
    When implementing ABC there are several decisions to make, including:
    \begin{itemize}
      \item What theorised model $f(\cdot|\pmb\theta,\x)$ to use.
      \item What kernel $K_\epsilon(\cdot)$ to use.
      \item What summary statistics $s(\cdot)$ to use.
      \item Do we even need summary statistics?
      \item How long to sample for?
    \end{itemize}
  \end{remark}

  \begin{proposition}{Kernels $K_\epsilon(\cdot)$}
    A \textit{Kernel} is used to determine with what probability to accept a sample, given it is a certain distance away from observed data. Here are some common kernels
    \begin{itemize}
      \item \textit{Uniform Kernel} $K_\epsilon(\|\mathbf{s}-\mathbf{s}_{obs}\|):=\indexed\{\|\mathbf{s}-\mathbf{s}_{obs}\|\leq\epsilon\}$ which accepts simulated values if they are within $\epsilon$ of observed data.
      \item \textit{Epanechnikov Kernel} $K_\epsilon(\|\mathbf{s}-\mathbf{s}_{obs}\|):=\frac3{4\epsilon}\left(1-\left(\frac{\|\mathbf{s}-\mathbf{s}_{obs}\|}\epsilon\right)^2\right)$ for $\|\mathbf{s}-\mathbf{s}_{obs}\|\leq\epsilon$
      \item \textit{Gaussian Kernel} $K(\|\mathbf{s}-\mathbf{s}_{obs}\|):=\frac1{\sqrt{2\pi}}e^{-\frac12\|\mathbf{s}-\mathbf{s}_{obs}\|^2}$
    \end{itemize}
  \end{proposition}

  \begin{proposition}{Summary Statistics $s(\cdot)$}
    See \texttt{SummaryStatisticSelection.pdf}
  \end{proposition}

  \begin{proposition}{How long to sample for}
    The algorithm given in \texttt{Proposition 1.3} runs the algorithm until a sufficiently large sample has been produced. This is not ideal as the algorithm will run for an unknown period of time and is dependent upon the kernel $K_\epsilon(\cdot)$ which has been defined.
    \par Alternatively, all simulated values could be kept and then all but the best $M$\footnote{$M$ closest to $s_\text{obs}$.} are discarded.
  \end{proposition}

\section{ABC Algorithms}

  \begin{proposition}{ABC Algorithm - Rejection}
    Consider the setup in \texttt{Proposition 1.2}. Here is a simple, online algorithm for ABC
    \begin{enumerate}
      \item Sample a set of parameters from the prior $\tilde{\pmb\theta}_t\sim\pi_0(\pmb\theta)$.
      \item Sample from the theorised model using these sampled parameters
      \[ \mathbf{y}_t\sim f_\mathcal{T}(\mathbf{y}|\tilde{\pmb\theta}_t) \]
      \item Calculate the summary statistic values for the sampled values $\mathbf{s}_t=\mathbf{s}(\mathbf{y}_t)$.
      \item Reject the sample summary statistic value $\mathbf{s}_t$ with probability $K_\epsilon(\|\mathbf{s}_t-\mathbf{s}_{obs}\|)$ where ${\mathbf{s}_{obs}=s(\mathbf{y})}$.
      \item Repeat steps i)-iii) until a total of $M$ simulated values have been accepted.
    \end{enumerate}
    Our final sample contains a set of $M$ summary statistics, along with the parameter values $\pmb\theta$ and variable-space points $\x$, which produced them. This data can be used to approximate the posterior for the parameter values.
  \end{proposition}

  \begin{remark}{ABC-SMC}
    The idea behind \textit{ABC-Sequential Monte Carlo} is to initially use a kernel with a large acceptance range to produce a sample of parameters which v. roughly approximate of the posterior. And then to finese this sample to improve the posterior, by resampling and tightening the kernel.
  \end{remark}

  \begin{proposition}{ABC Algorithm - SMC\cite{Delayed_Acceptance_ABC_SMC}\cite{youtube_ABC_intro}\cite{doi:10.1098/rsif.2008.0172}}
    Consider the setup in \texttt{Proposition 1.2}. Here is a \textit{Sequential Monte-Carlo} algorithm for ABC
    \begin{itemize}
      \item \textit{Initialisation} - Choose a set of \textit{scaling parameters} $\{\epsilon_1,\dots,\epsilon_T\}$ which are increasingly tight\footnote{There are automatic methods where $\epsilon_{t+1}$ is calculated at the end of step $t$ st convergence is encouraged.}
      \[ \{\epsilon_1,\dots,\epsilon_T\}\text{ where }\epsilon_1>\dots>\epsilon_T\]
      Set $N$ to be the number of sets of parameters to sample, choose some summary statistics $s(\cdot)$ and observe $y_{obs}$ from the true model.
      \item \textit{Initial Sampling Step} - $t=1$.\footnote{Here a set of possible parameters $\Theta_1$ is generated.}\footnote{It is possible for the same set of parameters to appear in $\Theta_t$ multiple times.}
      \begin{enumerate}
        \item Sample a set of parameters $\tilde{\pmb\theta}_{1,i}$\[ \tilde{\pmb\theta}_1\sim\pi_0(\pmb\theta) \]
        \item Observe the theorised model $\mathcal{T}$ with these sampled parameters
        \[ \mathbf{y}_{1,i}\sim f_\mathcal{T}(\mathbf{y}|\tilde{\pmb\theta}_{1,i}) \]
        \item
        \begin{itemize}
          \item[\textit{If}] $K_{\epsilon_1}(\|s(\mathbf{y}_{1,i})-s(\mathbf{y}_{obs})\|)$:\footnote{Sample parameters are accepted by the kernel.}
          \begin{itemize}
            \item Store the sampled parameters $\tilde{\pmb\theta}_{1,i}$ in set $\Theta_1$.
            \item Set $w_{1,i}=\frac1N$ and increment $i$.
            \item \textit{If }$i==N$: move to \textit{Resampling Step}.
          \end{itemize}
        \end{itemize}
      \end{enumerate}
      \item \textit{Resampling Step} - $t=2,\dots,T$.\footnote{Here, we determine weightings for the sets of parameters found in the previous step. With the weightings representing posterior probabilities.}
      \begin{enumerate}
        \item Sample $\tilde{\pmb\theta}_{t,i}$ from set $\Theta_{t-1}$ with probability $w_{t-1,j}$.\format{The weights form a KDE.}
          \[ \prob(\pmb\theta_i^*=\tilde{\pmb\theta}_j)=w_{t-1,j}\text{ for }\tilde{\pmb\theta}_j\in\Theta_{t-1} \]
        \item Perturb the sample parameters slightly using a \textit{Pertubance Kernel} $K^*$ to get a slightly different parameter set $\pmb\theta^*_{t,i}$
          \[ \pmb\theta^*_{t,i}\sim K^*(\theta|\tilde{\pmb\theta}_{t,i}) \]
        \item \textit{If $\pmb\theta^*_{t,i}$ is impossible under the prior}:\footnote{ie $\pi_0(\pmb\theta^*_{t,i})=0$} return to i).
        \item Observe the theorised model $\mathcal{T}$ with these perturbed parameters
          \[ \mathbf{y}_{t,i}\sim f_\mathcal{T}(\mathbf{y}|\pmb\theta^*_{t,i}) \]
        \item \textit{If \underline{not} }$K_{\epsilon_t}(\|s(\mathbf{y}_{t,i})-s(\mathbf{y}_{obs})\|)$:\footnote{ie the observation is reject by the kernel} return to i).
        \item Add $\pmb\theta_{t,i}^*$ to $\Theta_t$ and assign it weight $w_{t,i}$
        \[ \tilde{w}_{t,i}=\frac{\pi_0(\pmb\theta_{t,i}^*)}{\sum_{j=1}^Nw_{t-1,j}\prob(K_t(\theta|\tilde{\pmb\theta}_{t,i})=\pmb\theta_{t,i}^*)\footnotemark} \]
        \footnotetext{Weighted sum of the probability this set of parameters $\pmb\theta_{t,i}^*$ could have been observed under another one of the previous samples.}
        \item \textit{If }$|\Theta_t|<N$: increment $i$ and return to i).
        \item Normalise weights
        \[ w_{t,i}=\frac{\tilde{w}_{t,i}}{\sum_{i=1}^Nw_{t,i}} \]
        \item Increment $t$.
      \end{enumerate}
    \end{itemize}
    Code for this can be found at \url{https://stats.stackexchange.com/a/328384}.
  \end{proposition}

  \begin{proposition}{ABC Algorithm - MCMC\cite{ABC_MCMC_Intro}}
    Consider the setup in \texttt{Proposition 1.2}. Here is a \textit{Markov Chain Monte-Carlo} algorithm for \textit{ABC}
    \begin{itemize}
      \item \textit{Initialisation} - Observe $y_{obs}$ from the true model, choose some summary statistics $s(\cdot)$, define the length of the chain $N$\footnote{This is used for the termination condition, but other termination conditions are common. Most are based around spotting convergence.}, a theorised model $\mathacal{T}$ with pdf $f_\mathcal{T}(\cdot|\pmb\theta)$, define a prior for the priors $\pi_0(\pmb\theta)$ and a pertubance kernel $K^*(\cdot)$\footnote{e.g. Add some gaussian noise.}.
      \item \textit{Starting Sample}
      \begin{enumerate}
        \item Sample $\tilde{\pmb\theta}_0\sim\pi(\pmb\theta)$.
        \item Observe $y$ from the theorised model $\mathcal{T}$ using these sampled parameter $\pmb\theta_0$.
        \[ y\sim f_\mathcal{T}(y|\tilde{\pmb\theta}_0) \]
        \item
        \begin{itemize}
          \item[\textit{If}]$K_{\epsilon}(\|s(y)-s(y_{obs})\|)$: move to \textit{MCMC Step}.
          \item[\textit{Else}]: return to i).
        \end{itemize}
      \end{enumerate}
      \item \textit{MCMC Step}.
      \begin{enumerate}
        \item For $t\in[1,N]:$
        \begin{enumerate}
          \item Perturb the previous parameter value $\tilde{\pmb\theta}_{t-1}$ to get a new value $\pmb\theta^*$.
          \[ \pmb\theta^*=K^*(\tilde{\pmb\theta}_{t-1}) \]
          \item Observe $y$ from the theorised model $\mathcal{T}$ using these perturbed parameters $\pmb\theta^*$.
          \[ y\sim f_\mathcal{T}(y|\tilde{\pmb\theta}_0) \]
          \item
          \begin{itemize}
            \item[\textit{If}]$K_{\epsilon}(\|s(y)-s(y_{obs})\|)$: Set $\tilde{\pmb\theta}_t=\pmb\theta^*$.
            \item[\textit{Else}]: Set $\tilde{\pmb\theta}_t=\tilde{\pmb\theta}_{t-1}$.
          \end{itemize}
        \end{enumerate}
      \end{enumerate}
      \item Produce a posterior from the accepted parameter values $\{\tilde{\pmb\theta}_0,\dots,\tilde{\pmb\theta}_N\}$
    \end{itemize}
  \end{proposition}

\section{Semi-Automatic ABC}

  \begin{definition}{Semi-Automatic ABC\cite{Constructing_Summary_Statistics_For_ABC}}
    In \textit{Semi-Automatic ABC} summary statistics are learnt from simulation, but the user still has to make choices around what transformation $\mathbf{f}(\cdot)$ of simulated data $\mathbf{y}$.
    \par An application of \textit{Semi-Automatic ABC} should perform better in a general setting than traditional \textit{ABC}.
  \end{definition}

  \begin{proposition}{Semi-Automatic ABC - Algorithm}
    \begin{enumerate}
      \item Perform a pilot run of ABC\footnote{We need to define some arbitrary summary-statistics for this.} to determine a training-region of non-negligible posterior mass.
      \item for $t\in[1,M]$:
      \begin{enumerate}
        \item Simulate parameters $\pmb\theta_t$ from our prior $\pi_0(\pmb\theta)$, with the prior truncated to the training-region determined in (i).
        \item Simulate results $\mathbf{y}_t\sim f(\mathbf{y}|\pmb\theta_t)$ using these parameters.
      \end{enumerate}
      \item Use simulated data and parameter values to estimate summary statistics.\footnote{Potential methods inc. linear-regression, lasso analysis, cross-correlation analysis.}
      \item Run ABC with these estimated-summary statistics.
    \end{enumerate}
  \end{proposition}

  \begin{remark}{Step iii)}
    In step iii) we have simulated data $\mathcal{D}:=\{(\pmb\theta_1,\mathbf{y}_1),\dots,(\pmb\theta_M,\mathbf{y}_M)\}$ where $\pmb\theta_t\in\reals^m,\ \mathbf{y}_t\in\reals_t^n\ \forall\ t\in[1,M]$. We want to learn a transformation $f(\mathbf{y}_t)$ of the simulated data $\mathbf{y}_t$ st the parameters $\pmb\theta_t$ can be learnt from the transformation.
    \par A \textit{Liner Regression} approach is to learn the pick a function $\mathbf{f}:\reals^n\to\reals^m$\footnote{This transformation can actually map to any dimension but we prefer for it to be a lower dimension that the simulated data $\mathbf{y}$.} which maps the simulated data $\x_t$ to the same dimension as the simulated parameters (ie to $m$ dimensions) and then the parameters $\pmb\beta_0,\pmb\theta_1$ which give the least total-error across the whole data set $\mathcal{D}$\footnote{Generally least-square-error.} for the following
    \[\begin{array}{rcl}
      \pmb\theta_t&=&\pmb\beta_0+\pmb\beta_1\cdot \mathbf{f}(\mathbf{y}_t)+\varepsilon_t\\
      \Leftrightarrow[\pmb\theta_t]_i&=&[\pmb\beta_0]_i+[\pmb\beta_1]_i\cdot[\mathbf{f}(\mathbf{y}_t)]_i+[\varepsilon_t]_i\\
    \end{array}\]
    Our estimate for the model parameters $\pmb\theta$, given some data $\mathbf{y}$, is thus the fitted value
    \[ \hat{\pmb\theta}=\expect[\pmb\theta|\mathbf{y}]=\hat{\pmb\beta}_0+\hat{\pmb\beta}_1 \mathbf{f}(\pmb{y}) \]
    The constant terms $\hat{\pmb\beta}_0$ can be ignored as ABC only uses the distance between summary statistics (not their absolute value). This means our $m$ summary statistics are the different dimensions of $\hat{\pmb\beta}_1\mathbf{f}(\cdot)$
  \end{remark}

  \begin{remark}{Choosing transformation $\mathbf{f}(\cdot)$}
    In \texttt{Remark 1.2}  the user has to define how to transform the simulated results (ie define $\mathbf{f}(\cdot)$) and this choice will affect the set of summary statistics generated. It is easy to run this stage multiple times, using different transformations on the same data $\mathcal{D}$ and then using standard model comparison procedures\footnote{e.g. BIC, sufficiency} to determine which of the generate summary statistics are sufficient.
  \end{remark}

\newpage
\bibliographystyle{unsrt}
\bibliography{aside_bib}

\end{document}
